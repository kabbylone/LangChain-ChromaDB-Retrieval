{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOx8AVs3sHMhdwqp6gO9BQR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kabbylone/LangChain-ChromaDB-Retrieval/blob/main/Mistral_LLM_PDF_Retrieval.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain huggingface_hub sentence_transformers faiss-cpu unstructured chromadb Cython tiktoken unstructured[local-inference] -q"
      ],
      "metadata": {
        "collapsed": true,
        "id": "tRNon5hUzA4W"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "import os\n",
        "\n",
        "if \"HUGGINGFACEHUB_API_TOKEN\" not in os.environ:\n",
        "    os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = getpass.getpass(\"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\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TBZt3Z-tzBZa",
        "outputId": "2a1559ef-5b35-4a72-ff96-7ed691e0f572"
      },
      "execution_count": 2,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "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··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain-community"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9rl5QONQ1mK8",
        "outputId": "c627d144-1217-4d5a-d01a-55755d93a473"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain-community in /usr/local/lib/python3.10/dist-packages (0.2.1)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.0.30)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (3.9.5)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.6.6)\n",
            "Requirement already satisfied: langchain<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.2.1)\n",
            "Requirement already satisfied: langchain-core<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.2.1)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.1.63)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (1.25.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (8.3.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (4.0.3)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.21.2)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain<0.3.0,>=0.2.0->langchain-community) (0.2.0)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain<0.3.0,>=0.2.0->langchain-community) (2.7.1)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.0->langchain-community) (1.33)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.0->langchain-community) (23.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain-community) (3.10.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (2024.2.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (4.11.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.0.3)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.0->langchain-community) (2.4)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.0->langchain-community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.0->langchain-community) (2.18.2)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import UnstructuredPDFLoader\n",
        "from langchain.indexes import VectorstoreIndexCreator"
      ],
      "metadata": {
        "id": "Yq8A7-ph0YqG"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)\n",
        "\n",
        "pdf_folder_path = '/content/gdrive/My Drive/pdfs/'\n",
        "os.listdir(pdf_folder_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PMSwEVZlEeu6",
        "outputId": "174bd305-90d6-42de-efcf-69b7e1f229e5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Research and analysis on the development of intelligent toilet.pdf',\n",
              " 'Perceived Use Cases, Barriers, and Requirements for a Smart.pdf',\n",
              " 'Risks and benefits of smart toilets.pdf']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loaders = [UnstructuredPDFLoader(os.path.join(pdf_folder_path, fn)) for fn in os.listdir(pdf_folder_path)]\n",
        "loaders"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "xUbxlxsv1d88",
        "outputId": "95efe262-7054-419a-83ee-381e22cba115"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<langchain_community.document_loaders.pdf.UnstructuredPDFLoader at 0x7eb267fcf8e0>,\n",
              " <langchain_community.document_loaders.pdf.UnstructuredPDFLoader at 0x7eb243c4f160>,\n",
              " <langchain_community.document_loaders.pdf.UnstructuredPDFLoader at 0x7eb2426a64a0>]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains.question_answering import load_qa_chain\n",
        "from langchain import HuggingFaceHub\n",
        "from langchain_community.llms import HuggingFaceEndpoint\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.text_splitter import CharacterTextSplitter"
      ],
      "metadata": {
        "id": "ig5a6ctOHgmM"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index = VectorstoreIndexCreator(\n",
        "    embedding=HuggingFaceEmbeddings(),\n",
        "    text_splitter=CharacterTextSplitter(chunk_size=800, chunk_overlap=130)).from_loaders(loaders)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "4iCTeaQm1zOY",
        "outputId": "b3a1dcbd-b849-481a-a800-559268d25398"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain/indexes/vectorstore.py:129: UserWarning: Using InMemoryVectorStore as the default vectorstore.This memory store won't persist data. You should explicitlyspecify a vectorstore when using VectorstoreIndexCreator\n",
            "  warnings.warn(\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 902, which is longer than the specified 800\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 1506, which is longer than the specified 800\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 1094, which is longer than the specified 800\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 1365, which is longer than the specified 800\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 994, which is longer than the specified 800\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 1002, which is longer than the specified 800\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 1001, which is longer than the specified 800\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 881, which is longer than the specified 800\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 1374, which is longer than the specified 800\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 1011, which is longer than the specified 800\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 903, which is longer than the specified 800\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 1008, which is longer than the specified 800\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 1875, which is longer than the specified 800\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 1508, which is longer than the specified 800\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 837, which is longer than the specified 800\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 953, which is longer than the specified 800\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 811, which is longer than the specified 800\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 1354, which is longer than the specified 800\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 1315, which is longer than the specified 800\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 1229, which is longer than the specified 800\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 862, which is longer than the specified 800\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 1236, which is longer than the specified 800\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 1013, which is longer than the specified 800\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 914, which is longer than the specified 800\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 833, which is longer than the specified 800\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 1242, which is longer than the specified 800\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 1807, which is longer than the specified 800\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 1613, which is longer than the specified 800\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 891, which is longer than the specified 800\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 1592, which is longer than the specified 800\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 815, which is longer than the specified 800\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 976, which is longer than the specified 800\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 945, which is longer than the specified 800\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 883, which is longer than the specified 800\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 1039, which is longer than the specified 800\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 1224, which is longer than the specified 800\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 802, which is longer than the specified 800\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 888, which is longer than the specified 800\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm=HuggingFaceEndpoint(repo_id=\"mistralai/Mistral-7B-Instruct-v0.2\", temperature=0.1, max_length=512)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "IA1EPDAE16Zj",
        "outputId": "62f064b1-3338-4dfe-94be-2668040738f0"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The class `HuggingFaceEndpoint` was deprecated in LangChain 0.0.37 and will be removed in 0.3. An updated version of the class exists in the from langchain-huggingface package and should be used instead. To use it run `pip install -U from langchain-huggingface` and import as `from from langchain_huggingface import llms import HuggingFaceEndpoint`.\n",
            "  warn_deprecated(\n",
            "WARNING:langchain_community.llms.huggingface_endpoint:WARNING! max_length is not default parameter.\n",
            "                    max_length was transferred to model_kwargs.\n",
            "                    Please make sure that max_length is what you intended.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
            "Token is valid (permission: read).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import RetrievalQA\n",
        "chain = RetrievalQA.from_chain_type(llm=llm,\n",
        "                                    chain_type=\"stuff\",\n",
        "                                    retriever=index.vectorstore.as_retriever(),\n",
        "                                    input_key=\"question\")"
      ],
      "metadata": {
        "id": "xwoANlsW18fA"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain.run('Who are the authors of Perceived Use Cases, Barriers, and Requirements for a Smart Health-Tracking Toilet Seat')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "id": "VFMoDdR02ALz",
        "outputId": "e0b822e5-7c07-43f8-b8a2-a61b52bf0ae7"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 0.3.0. Use invoke instead.\n",
            "  warn_deprecated(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' Sander Hermsen, Vera Verbiest, Marije Buijs, and Eva Wentink are the authors of the paper \"Perceived Use Cases, Barriers, and Requirements for a Smart Health-Tracking Toilet Seat.\"'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chain.run('Who are the authors of Research and analysis on the development of intelligent toilet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "id": "tz1YwdRxH4qd",
        "outputId": "39bc4c65-d3ba-41c0-e1ee-b40672ed7148"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' Ming Gong, Kejing Li, Tao Tian, Xianbian Mao, and Chen Wang.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_tSfIJuAICFD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}